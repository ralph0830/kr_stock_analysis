"""
News Scorer
ë‰´ìŠ¤ ì ìˆ˜í™” - ì¢…ê°€ë² íŒ… V2 ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚°
"""

import logging
from typing import List, Dict, Any
from datetime import date
from dataclasses import dataclass

from src.analysis.sentiment_analyzer import SentimentAnalyzer, SentimentResult, Sentiment

logger = logging.getLogger(__name__)


@dataclass
class NewsScoreResult:
    """ì¼ì¼ ë‰´ìŠ¤ ì ìˆ˜ ê²°ê³¼"""
    date: date
    total_score: float  # ì´ì  (0~3ì )
    positive_count: int  # ê¸ì • ë‰´ìŠ¤ ìˆ˜
    negative_count: int  # ë¶€ì • ë‰´ìŠ¤ ìˆ˜
    neutral_count: int  # ì¤‘ë¦½ ë‰´ìŠ¤ ìˆ˜
    details: List[Dict[str, Any]]  # ê°œë³„ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼


class NewsScorer:
    """
    ë‰´ìŠ¤ ì ìˆ˜í™”ê¸°

    ì¢…ê°€ë² íŒ… V2 ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚° (0~3ì )
    """

    def __init__(self, api_key: str | None = None):
        """
        ë‰´ìŠ¤ ì ìˆ˜í™”ê¸° ì´ˆê¸°í™”

        Args:
            api_key: Gemini API í‚¤ (Noneì´ë©´ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©)
        """
        self.analyzer = SentimentAnalyzer(api_key)

    def calculate_daily_score(
        self,
        ticker: str,
        articles: List[Dict[str, str]],
        target_date: date,
    ) -> NewsScoreResult:
        """
        ì¼ì¼ ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚°

        **ì ìˆ˜ ì‚°ì • ê¸°ì¤€:**
        - 3ì : ë§¤ìš° ê¸ì •ì  (ê¸ì • ë‰´ìŠ¤ 3ê°œ ì´ìƒ or í‰ê·  ì ìˆ˜ 0.6+)
        - 2ì : ê¸ì •ì  (ê¸ì • ë‰´ìŠ¤ 2ê°œ or í‰ê·  ì ìˆ˜ 0.3+)
        - 1ì : ì•½ê°„ ê¸ì • (ê¸ì • ë‰´ìŠ¤ 1ê°œ)
        - 0ì : ì¤‘ë¦½ (ê¸ì •/ë¶€ì • ê· í˜•)
        - ìŒìˆ˜: ë¶€ì •ì  (ì¢…ê°€ë² íŒ…ì—ì„œëŠ” ì œì™¸)

        Args:
            ticker: ì¢…ëª©ì½”ë“œ
            articles: ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ [{title, content, source}, ...]
            target_date: ëŒ€ìƒ ë‚ ì§œ

        Returns:
            ì¼ì¼ ë‰´ìŠ¤ ì ìˆ˜ ê²°ê³¼
        """
        if not articles:
            return NewsScoreResult(
                date=target_date,
                total_score=0.0,
                positive_count=0,
                negative_count=0,
                neutral_count=0,
                details=[],
            )

        # ê°ì„± ë¶„ì„
        results = []
        for article in articles:
            try:
                result = self.analyzer.analyze(
                    title=article["title"],
                    content=article.get("content", ""),
                )
                results.append(result)
            except Exception as e:
                logger.error(f"âŒ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {e}, title={article['title']}")
                # ì‹¤íŒ¨ ì‹œ ì¤‘ë¦½ ê²°ê³¼ë¡œ ì²˜ë¦¬ (í´ë°±)
                from src.analysis.sentiment_analyzer import SentimentResult
                results.append(SentimentResult(
                    sentiment=Sentiment.NEUTRAL,
                    confidence=0.0,
                    keywords=[],
                    summary=f"[ë¶„ì„ ì‹¤íŒ¨] {article['title'][:30]}...",
                    score=0.0,
                ))

        # í†µê³„ ì§‘ê³„
        positive_count = sum(1 for r in results if r.sentiment == Sentiment.POSITIVE)
        negative_count = sum(1 for r in results if r.sentiment == Sentiment.NEGATIVE)
        neutral_count = sum(1 for r in results if r.sentiment == Sentiment.NEUTRAL)

        # í‰ê·  ê°ì„± ì ìˆ˜ ê³„ì‚°
        avg_score = sum(r.score for r in results) / len(results)

        # ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚° (0~3ì )
        if positive_count >= 3 or avg_score >= 0.6:
            total_score = 3.0
        elif positive_count == 2 or avg_score >= 0.3:
            total_score = 2.0
        elif positive_count == 1:
            total_score = 1.0
        elif negative_count > positive_count:
            # ë¶€ì •ì ì¼ ê²½ìš° ìŒìˆ˜ ì ìˆ˜
            total_score = max(-3.0, -float(negative_count))
        else:
            total_score = 0.0

        # ìƒì„¸ ê²°ê³¼ ìƒì„±
        details = []
        for i, (article, result) in enumerate(zip(articles, results)):
            details.append(
                {
                    "title": article["title"],
                    "source": article.get("source", "Unknown"),
                    "sentiment": result.sentiment.value,
                    "confidence": result.confidence,
                    "score": result.score,
                    "keywords": result.keywords,
                }
            )

        logger.info(
            f"ğŸ“Š {ticker} {target_date} ë‰´ìŠ¤ ì ìˆ˜: {total_score:.1f} "
            f"(ê¸ì •: {positive_count}, ë¶€ì •: {negative_count}, ì¤‘ë¦½: {neutral_count})"
        )

        return NewsScoreResult(
            date=target_date,
            total_score=max(0.0, total_score),  # ì¢…ê°€ë² íŒ…ì—ì„œëŠ” ìŒìˆ˜ ì œê±°
            positive_count=positive_count,
            negative_count=negative_count,
            neutral_count=neutral_count,
            details=details,
        )

    def calculate_weekly_score(
        self,
        ticker: str,
        weekly_articles: Dict[date, List[Dict[str, str]]],
    ) -> float:
        """
        ì£¼ê°„ ë‰´ìŠ¤ ì ìˆ˜ ì§‘ê³„

        Args:
            ticker: ì¢…ëª©ì½”ë“œ
            weekly_articles: ì¼ìë³„ ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ {date: [articles]}

        Returns:
            ì£¼ê°„ í‰ê·  ë‰´ìŠ¤ ì ìˆ˜ (0~3ì )
        """
        if not weekly_articles:
            return 0.0

        daily_scores = []
        for target_date, articles in weekly_articles.items():
            result = self.calculate_daily_score(ticker, articles, target_date)
            daily_scores.append(result.total_score)

        weekly_avg = sum(daily_scores) / len(daily_scores) if daily_scores else 0.0

        logger.info(
            f"ğŸ“Š {ticker} ì£¼ê°„ ë‰´ìŠ¤ ì ìˆ˜: {weekly_avg:.1f} "
            f"(ì¼ìˆ˜: {len(weekly_articles)}, ì¼ì¼ ì ìˆ˜: {[f'{s:.1f}' for s in daily_scores]})"
        )

        return weekly_avg

    def extract_keywords(self, articles: List[Dict[str, str]]) -> List[str]:
        """
        ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œ

        Args:
            articles: ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìƒìœ„ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ë¹ˆë„ìˆœ)
        """
        keyword_freq = {}

        for article in articles:
            result = self.analyzer.analyze(
                title=article["title"],
                content=article.get("content", ""),
            )

            for keyword in result.keywords:
                keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1

        # ë¹ˆë„ìˆœ ì •ë ¬
        sorted_keywords = sorted(
            keyword_freq.items(), key=lambda x: x[1], reverse=True
        )

        return [keyword for keyword, _ in sorted_keywords[:10]]
