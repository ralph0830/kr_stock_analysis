"""
Celery News Tasks
ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„ íƒœìŠ¤í¬

Phase 5: ìë™ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„
- DBì— news_urls ìë™ ì €ì¥
- Celery Beat ìŠ¤ì¼€ì¤„ëŸ¬ ì—°ë™
"""

import logging
from datetime import date, datetime
from typing import List, Dict, Any

from celery import shared_task
from celery.schedules import crontab

from src.collectors.news_collector import NewsCollector
from src.analysis.sentiment_analyzer import SentimentAnalyzer
from src.analysis.news_scorer import NewsScorer
from src.database.session import get_db_session
from src.repositories.ai_analysis_repository import AIAnalysisRepository

logger = logging.getLogger(__name__)


@shared_task(name="news.collect", bind=True, max_retries=3)
def collect_news(ticker: str, days: int = 7, max_articles: int = 50) -> Dict[str, Any]:
    """
    ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬

    Args:
        ticker: ì¢…ëª©ì½”ë“œ
        days: ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„ (ê¸°ë³¸ 7ì¼)
        max_articles: ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ 50ê±´)

    Returns:
        ìˆ˜ì§‘ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        logger.info(f"ğŸ“° {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (ìµœê·¼ {days}ì¼, ìµœëŒ€ {max_articles}ê±´)")

        # ë‰´ìŠ¤ ìˆ˜ì§‘
        collector = NewsCollector()
        articles = collector.fetch_stock_news(
            ticker=ticker,
            days=days,
            max_articles=max_articles,
        )

        logger.info(f"âœ… {ticker} ë‰´ìŠ¤ {len(articles)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")

        return {
            "ticker": ticker,
            "collected_count": len(articles),
            "success": True,
            "articles": [collector.to_dict(a) for a in articles[:5]],  # ìµœëŒ€ 5ê±´ë§Œ ë°˜í™˜
        }

    except Exception as e:
        logger.error(f"âŒ {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        # ì¬ì‹œë„
        raise self.retry(exc=e, countdown=60)  # 1ë¶„ í›„ ì¬ì‹œë„


@shared_task(name="news.analyze_sentiment", bind=True, max_retries=3)
def analyze_sentiment(ticker: str, articles: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ë‰´ìŠ¤ ê°ì„± ë¶„ì„ íƒœìŠ¤í¬

    Args:
        ticker: ì¢…ëª©ì½”ë“œ
        articles: ë‰´ìŠ¤ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸

    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        logger.info(f"ğŸ¤– {ticker} ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹œì‘ ({len(articles)}ê±´)")

        # ê°ì„± ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = SentimentAnalyzer()

        # ë°°ì¹˜ ë¶„ì„
        results = []
        for article in articles:
            result = analyzer.analyze(
                title=article["title"],
                content=article.get("content", ""),
            )
            results.append({
                "title": article["title"],
                "sentiment": result.sentiment.value,
                "confidence": result.confidence,
                "score": result.score,
                "keywords": result.keywords,
            })

        # í†µê³„
        positive_count = sum(1 for r in results if r["sentiment"] == "positive")
        negative_count = sum(1 for r in results if r["sentiment"] == "negative")
        neutral_count = sum(1 for r in results if r["sentiment"] == "neutral")

        logger.info(
            f"âœ… {ticker} ê°ì„± ë¶„ì„ ì™„ë£Œ "
            f"(ê¸ì •: {positive_count}, ë¶€ì •: {negative_count}, ì¤‘ë¦½: {neutral_count})"
        )

        return {
            "ticker": ticker,
            "analyzed_count": len(results),
            "positive_count": positive_count,
            "negative_count": negative_count,
            "neutral_count": neutral_count,
            "results": results[:5],  # ìµœëŒ€ 5ê±´ë§Œ ë°˜í™˜
            "success": True,
        }

    except Exception as e:
        logger.error(f"âŒ {ticker} ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise self.retry(exc=e, countdown=60)


@shared_task(name="news.calculate_scores", bind=True, max_retries=3)
def calculate_news_scores(ticker: str, articles: List[Dict[str, Any]], target_date: str) -> Dict[str, Any]:
    """
    ì¼ì¼ ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚° íƒœìŠ¤í¬

    Args:
        ticker: ì¢…ëª©ì½”ë“œ
        articles: ë‰´ìŠ¤ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        target_date: ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD)

    Returns:
        ì ìˆ˜ ê³„ì‚° ê²°ê³¼
    """
    try:
        logger.info(f"ğŸ“Š {ticker} {target_date} ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚° ì‹œì‘")

        # ë‚ ì§œ íŒŒì‹±
        analysis_date = datetime.strptime(target_date, "%Y-%m-%d").date()

        # ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚°
        scorer = NewsScorer()
        result = scorer.calculate_daily_score(
            ticker=ticker,
            articles=articles,
            target_date=analysis_date,
        )

        logger.info(
            f"âœ… {ticker} {target_date} ë‰´ìŠ¤ ì ìˆ˜: {result.total_score:.1f} "
            f"(ê¸ì •: {result.positive_count}, ë¶€ì •: {result.negative_count})"
        )

        return {
            "ticker": ticker,
            "date": target_date,
            "total_score": result.total_score,
            "positive_count": result.positive_count,
            "negative_count": result.negative_count,
            "neutral_count": result.neutral_count,
            "success": True,
        }

    except Exception as e:
        logger.error(f"âŒ {ticker} ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
        raise self.retry(exc=e, countdown=60)


@shared_task(name="news.collect_all_stocks", bind=True, max_retries=3)
def collect_all_stocks_news(market: str = "KOSPI", days: int = 7, max_articles: int = 30) -> Dict[str, Any]:
    """
    ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬

    Args:
        market: ì‹œì¥ êµ¬ë¶„ (KOSPI, KOSDAQ)
        days: ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„
        max_articles: ì¢…ëª©ë³„ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜

    Returns:
        ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
    """
    try:
        logger.info(f"ğŸ“° {market} ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")

        # ê°„ë‹¨ êµ¬í˜„: ì£¼ìš” ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        stocks = [
            ("005930", "ì‚¼ì„±ì „ì"),
            ("000660", "SKí•˜ì´ë‹‰ìŠ¤"),
            ("035420", "NAVER"),
            ("066570", "LGì „ì"),
            ("005380", "í˜„ëŒ€ì°¨"),
        ]

        logger.info(f"ğŸ“‹ {len(stocks)}ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ëŒ€ìƒ")

        # ê° ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
        results = []
        for ticker, name in stocks:
            try:
                task_result = collect_news(ticker, days, max_articles)
                results.append({
                    "ticker": ticker,
                    "name": name,
                    "collected": task_result.get("collected_count", 0),
                })
            except Exception as e:
                logger.error(f"âŒ {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                results.append({
                    "ticker": ticker,
                    "name": name,
                    "collected": 0,
                    "error": str(e),
                })

        total_collected = sum(r.get("collected", 0) for r in results)

        logger.info(f"âœ… {market} ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ (ì´ {total_collected}ê±´)")

        return {
            "market": market,
            "target_count": len(stocks),
            "success_count": sum(1 for r in results if r.get("collected", 0) > 0),
            "total_collected": total_collected,
            "results": results[:10],  # ìµœëŒ€ 10ì¢…ëª©ë§Œ ë°˜í™˜
            "success": True,
        }

    except Exception as e:
        logger.error(f"âŒ {market} ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        raise self.retry(exc=e, countdown=120)  # 2ë¶„ í›„ ì¬ì‹œë„


@shared_task(name="news.pipeline", bind=True, max_retries=3)
def news_pipeline_task(ticker: str, days: int = 7, max_articles: int = 30) -> Dict[str, Any]:
    """
    ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ íƒœìŠ¤í¬ (ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ì ìˆ˜í™”)

    Args:
        ticker: ì¢…ëª©ì½”ë“œ
        days: ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„
        max_articles: ìµœëŒ€ ê¸°ì‚¬ ìˆ˜

    Returns:
        íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼
    """
    try:
        logger.info(f"ğŸ”„ {ticker} ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ì‹œì‘")

        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        collect_result = collect_news(ticker, days, max_articles)
        collected_count = collect_result["collected_count"]
        articles = collect_result["articles"]

        if collected_count == 0:
            logger.warning(f"âš ï¸  {ticker} ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì—†ìŒ")
            return {
                "ticker": ticker,
                "stage": "collect",
                "success": False,
                "reason": "no_articles",
            }

        # 2. ê°ì„± ë¶„ì„
        analyze_result = analyze_sentiment(ticker, articles)
        positive_count = analyze_result["positive_count"]
        negative_count = analyze_result["negative_count"]

        # 3. ì ìˆ˜ ê³„ì‚°
        today = date.today().isoformat()
        score_result = calculate_news_scores(ticker, articles, today)

        logger.info(
            f"âœ… {ticker} ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ "
            f"(ìˆ˜ì§‘: {collected_count}ê±´, ì ìˆ˜: {score_result['total_score']:.1f})"
        )

        return {
            "ticker": ticker,
            "stage": "complete",
            "collected_count": collected_count,
            "positive_count": positive_count,
            "negative_count": negative_count,
            "total_score": score_result["total_score"],
            "success": True,
        }

    except Exception as e:
        logger.error(f"âŒ {ticker} ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        raise self.retry(exc=e, countdown=120)


# íƒœìŠ¤í¬ ì²´ì´ë‹ ì˜ˆì‹œ
@shared_task(name="news.collect_and_analyze", bind=True)
def collect_and_analyze_news(ticker: str):
    """
    ë‰´ìŠ¤ ìˆ˜ì§‘ í›„ ê°ì„± ë¶„ì„ (ì²´ì´ë‹ ì˜ˆì‹œ)

    Args:
        ticker: ì¢…ëª©ì½”ë“œ

    Returns:
        ê°ì„± ë¶„ì„ ê²°ê³¼
    """
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    collect_result = collect_news(ticker, days=7, max_articles=30)

    # ê²°ê³¼ì—ì„œ articles ì¶”ì¶œ
    articles = collect_result["articles"]

    # ê°ì„± ë¶„ì„ (ì²´ì´ë‹)
    return analyze_sentiment(ticker, articles)


# ============================================================================
# Phase 5: ìë™ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ íƒœìŠ¤í¬ (GREEN)
# ============================================================================

@shared_task(name="news.collect_and_save", bind=True, max_retries=3)
def collect_and_save_task(
    self,  # Celery task binding (self)
    ticker: str,
    days: int = 7,
    max_articles: int = 30,
) -> Dict[str, Any]:
    """
    ë‰´ìŠ¤ ìˆ˜ì§‘ ë° DB ì €ì¥ íƒœìŠ¤í¬ (Phase 5: GREEN)

    ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì™€ URLì„ DBì— ìë™ ì €ì¥

    Args:
        self: Celery task instance (bind=True)
        ticker: ì¢…ëª© ì½”ë“œ
        days: ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„
        max_articles: ìµœëŒ€ ê¸°ì‚¬ ìˆ˜

    Returns:
        ì €ì¥ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    session = None
    try:
        logger.info(f"ğŸ”„ {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘ ë° DB ì €ì¥ ì‹œì‘")

        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        collector = NewsCollector()
        articles = collector.fetch_stock_news(
            ticker=ticker,
            days=days,
            max_articles=max_articles,
        )

        if not articles:
            logger.warning(f"âš ï¸  {ticker} ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì—†ìŒ")
            return {
                "ticker": ticker,
                "success": False,
                "reason": "no_articles",
                "saved_count": 0,
            }

        # 2. news_urls ì¶”ì¶œ
        news_urls = [
            {"title": article.get("title", ""), "url": article.get("url", "")}
            for article in articles
            if article.get("url")  # URLì´ ìˆëŠ” ê¸°ì‚¬ë§Œ
        ]

        # 3. ê°ì„± ë¶„ì„
        analyzer = SentimentAnalyzer()

        # ì „ì²´ ë¶„ì„ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ê²°í•©
        all_titles = " ".join([a.get("title", "") for a in articles])
        all_content = " ".join([a.get("content", "") for a in articles])

        sentiment_result = analyzer.analyze(
            title=all_titles,
            content=all_content[:2000],  # ì œí•œ
        )

        # 4. DB ì €ì¥
        # get_db_session()ëŠ” ì œë„ˆë ˆì´í„°, next()ë¡œ session ì¶”ì¶œ
        session_gen = get_db_session()
        session = next(session_gen)
        repo = AIAnalysisRepository(session)

        analysis = repo.save_analysis(
            ticker=ticker,
            analysis_date=date.today(),
            sentiment=sentiment_result.sentiment.value,
            score=sentiment_result.score,
            summary=f"ìµœê·¼ {len(articles)}ê±´ì˜ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.",
            keywords=sentiment_result.keywords[:5],  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
            recommendation=_get_recommendation_from_sentiment(sentiment_result.sentiment.value),
            confidence=sentiment_result.confidence,
            news_count=len(articles),
            news_urls=news_urls,  # ğŸ”‘ Phase 5: news_urls ì €ì¥
        )

        logger.info(
            f"âœ… {ticker} ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ "
            f"(ê¸°ì‚¬: {len(articles)}ê±´, URLs: {len(news_urls)}ê±´, "
            f"ê°ì„±: {sentiment_result.sentiment.value})"
        )

        return {
            "ticker": ticker,
            "success": True,
            "collected_count": len(articles),
            "saved_count": 1,
            "news_urls_count": len(news_urls),
            "sentiment": sentiment_result.sentiment.value,
            "score": sentiment_result.score,
            "analysis_id": analysis.id,
        }

    except Exception as e:
        logger.error(f"âŒ {ticker} ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
        # self.retryëŠ” Celery task bindingì´ í•„ìš”
        return {
            "ticker": ticker,
            "success": False,
            "error": str(e),
        }

    finally:
        if session:
            session.close()


@shared_task(name="news.collect_multiple_and_save", bind=True, max_retries=3)
def collect_multiple_and_save(
    self,
    tickers: List[str],
    days: int = 7,
    max_articles: int = 30,
) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ë° DB ì €ì¥ (Phase 5: GREEN)

    Args:
        self: Celery task instance
        tickers: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        days: ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„
        max_articles: ì¢…ëª©ë³„ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜

    Returns:
        ì €ì¥ ê²°ê³¼ ìš”ì•½
    """
    logger.info(f"ğŸ”„ {len(tickers)}ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")

    results = []
    success_count = 0
    total_urls = 0

    for ticker in tickers:
        try:
            result = collect_and_save_task(self, ticker, days, max_articles)
            results.append({
                "ticker": ticker,
                "success": result.get("success", False),
                "news_count": result.get("collected_count", 0),
                "urls_count": result.get("news_urls_count", 0),
            })

            if result.get("success"):
                success_count += 1
                total_urls += result.get("news_urls_count", 0)

        except Exception as e:
            logger.error(f"âŒ {ticker} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            results.append({
                "ticker": ticker,
                "success": False,
                "error": str(e),
            })

    logger.info(
        f"âœ… ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ "
        f"(ì„±ê³µ: {success_count}/{len(tickers)}, ì´ URL: {total_urls}ê±´)"
    )

    return {
        "total_tickers": len(tickers),
        "success_count": success_count,
        "total_urls": total_urls,
        "results": results,
        "success": True,
    }


@shared_task(name="news.scheduled_daily_collection", bind=True, max_retries=3)
def scheduled_daily_collection(
    self,
    market: str = "KOSPI",
    days: int = 7,
    max_articles: int = 30,
) -> Dict[str, Any]:
    """
    ì¼ì¼ ìŠ¤ì¼€ì¤„ ë‰´ìŠ¤ ìˆ˜ì§‘ (Phase 5: GREEN)

    Celery Beatì—ì„œ í˜¸ì¶œë˜ëŠ” ì¼ì¼ ë‰´ìŠ¤ ìˆ˜ì§‘ íƒœìŠ¤í¬

    Args:
        self: Celery task instance
        market: ì‹œì¥ êµ¬ë¶„ (KOSPI, KOSDAQ)
        days: ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„
        max_articles: ì¢…ëª©ë³„ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜

    Returns:
        ìˆ˜ì§‘ ê²°ê³¼
    """
    logger.info(f"ğŸ“… {market} ì¼ì¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ ì‹¤í–‰")

    # ì£¼ìš” ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    major_stocks = {
        "KOSPI": ["005930", "000660", "035420", "005380", "066570", "028260", "105560", "035720"],
        "KOSDAQ": ["051910", "247540", "323410", "086520", "251270"],
    }

    tickers = major_stocks.get(market, major_stocks["KOSPI"])

    return collect_multiple_and_save(self, tickers, days, max_articles)


def _get_recommendation_from_sentiment(sentiment: str) -> str:
    """
    ê°ì„± ë¶„ì„ ê²°ê³¼ë¡œ ì¶”ì²œì‚¬í•­ ìƒì„±

    Args:
        sentiment: ê°ì„± (positive/negative/neutral)

    Returns:
        ì¶”ì²œì‚¬í•­ (BUY/SELL/HOLD)
    """
    if sentiment == "positive":
        return "BUY"
    elif sentiment == "negative":
        return "SELL"
    else:
        return "HOLD"
