# Ralph Stock Analysis - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ê³„ì„œ

**ì‘ì„±ì¼**: 2026-02-06
**ì‘ì„±ì**: DevOps Architect (Claude Code Agent)
**ë²„ì „**: 1.0

---

## 1. ê°œìš”

### 1.1 ëª©í‘œ
- **ê°€ì‹œì„± í™•ë³´**: ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- **ì‹ ì†í•œ ì¥ì•  ê°ì§€**: 1ë¶„ ì´ë‚´ ì¥ì•  ì•Œë¦¼
- **ì„±ëŠ¥ ìµœì í™”**: ë³‘ëª© ì§€ì  ì‹ë³„ ë° ê°œì„ 
- **ìš©ëŸ‰ ê³„íš**: ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ì¶”ì´ ë¶„ì„

### 1.2 ë²”ìœ„
- **Metrics**: Prometheus + Grafana
- **Logs**: ELK Stack (Elasticsearch, Logstash, Kibana)
- **Alerts**: AlertManager + PagerDuty/Slack
- **Health Check**: í†µí•© í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ

---

## 2. ì•„í‚¤í…ì²˜

### 2.1 ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Monitoring Stack                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Grafana  â”‚â—„â”€â”€â”€â”¤Prometheusâ”‚â—„â”€â”€â”€â”¤Exporter  â”‚â—„â”€â”€â”€â”¤ Services â”‚     â”‚
â”‚  â”‚ :3000    â”‚    â”‚ :9090    â”‚    â”‚  9100+   â”‚    â”‚          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                        â”‚                                              â”‚
â”‚                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                       â”‚
â”‚                   â”‚AlertMana â”‚                                       â”‚
â”‚                   â”‚  :9093   â”‚                                       â”‚
â”‚                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                        â”‚                                              â”‚
â”‚                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                       â”‚
â”‚                   â”‚ Slack    â”‚                                       â”‚
â”‚                   â”‚ Email    â”‚                                       â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Logging Stack                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Kibana  â”‚â—„â”€â”€â”€â”¤Logstash  â”‚â—„â”€â”€â”€â”¤Filebeat  â”‚â—„â”€â”€â”€â”¤ Services â”‚     â”‚
â”‚  â”‚ :5601    â”‚    â”‚ :5044    â”‚    â”‚  (log)   â”‚    â”‚          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                       â”‚                                              â”‚
â”‚                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                       â”‚
â”‚                  â”‚Elasticsearch                                    â”‚
â”‚                  â”‚ :9200    â”‚                                       â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Exporter êµ¬ì„±

| Exporter | Port | ìˆ˜ì§‘ ë©”íŠ¸ë¦­ | ëŒ€ìƒ |
|----------|------|-------------|------|
| Node Exporter | 9100 | CPU, Memory, Disk, Network | Host ì‹œìŠ¤í…œ |
| cAdvisor | 9800 | Container CPU/Memory/Network | Docker ì»¨í…Œì´ë„ˆ |
| PostgreSQL Exporter | 9187 | Connections, Queries, Replication | PostgreSQL |
| Redis Exporter | 9121 | Commands, Connections, Memory | Redis |
| Celery Exporter | 9540 | Tasks, Workers, Brokers | Celery |
| FastAPI Exporter | 8000 | Custom metrics | Python Services |

---

## 3. Prometheus êµ¬ì„±

### 3.1 ì„¤ì¹˜ ê³„íš

#### Docker Compose ì¶”ê°€
```yaml
# docker/compose/services/monitoring.yml

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - ralph-network

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - ralph-network

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./config/alertmanager:/etc/alertmanager
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - ralph-network

  # Node Exporter - Host ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - ralph-network

  # cAdvisor - ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    restart: unless-stopped
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    networks:
      - ralph-network

  # PostgreSQL Exporter
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    restart: unless-stopped
    environment:
      - DATA_SOURCE_NAME=postgresql://postgres:postgres@postgres:5432/ralph_stock?sslmode=disable
    networks:
      - ralph-network

  # Redis Exporter
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    restart: unless-stopped
    environment:
      - REDIS_ADDR=redis://redis:6379
    networks:
      - ralph-network

volumes:
  prometheus-data:
    name: ralph-prometheus-data
  grafana-data:
    name: ralph-grafana-data
  alertmanager-data:
    name: ralph-alertmanager-data
```

### 3.2 Prometheus ì„¤ì •

```yaml
# docker/compose/config/prometheus/prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'ralph-stock'
    environment: 'production'

# AlertManager ê´€ë¦¬
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

# ì•Œë¦¼ ê·œì¹™ ë¡œë“œ
rule_files:
  - 'alerts/*.yml'

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ëŒ€ìƒ
scrape_configs:
  # Prometheus ìì²´ ë©”íŠ¸ë¦­
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # API Gateway
  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:5111']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # VCP Scanner
  - job_name: 'vcp-scanner'
    static_configs:
      - targets: ['vcp-scanner:5112']
    metrics_path: '/metrics'

  # Signal Engine
  - job_name: 'signal-engine'
    static_configs:
      - targets: ['signal-engine:5113']
    metrics_path: '/metrics'

  # Daytrading Scanner
  - job_name: 'daytrading-scanner'
    static_configs:
      - targets: ['daytrading-scanner:5115']
    metrics_path: '/metrics'

  # Chatbot
  - job_name: 'chatbot'
    static_configs:
      - targets: ['chatbot:5114']
    metrics_path: '/metrics'

  # PostgreSQL
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Node Exporter (ì‹œìŠ¤í…œ)
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

  # cAdvisor (ì»¨í…Œì´ë„ˆ)
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
```

### 3.3 Alert ê·œì¹™

```yaml
# docker/compose/config/prometheus/alerts/services.yml

groups:
  - name: service_health
    interval: 30s
    rules:
      # ì„œë¹„ìŠ¤ ë‹¤ìš´ ê°ì§€
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "ì„œë¹„ìŠ¤ ë‹¤ìš´: {{ $labels.instance }}"
          description: "{{ $labels.job }} ì„œë¹„ìŠ¤ê°€ 1ë¶„ ì´ìƒ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

      # ë†’ì€ ì˜¤ë¥˜ìœ¨
      - alert: HighErrorRate
        expr: |
          (
            rate(http_requests_total{status=~"5.."}[5m])
            /
            rate(http_requests_total[5m])
          ) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ë†’ì€ ì˜¤ë¥˜ìœ¨: {{ $labels.instance }}"
          description: "5xx ì˜¤ë¥˜ìœ¨ì´ 5% ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value | humanizePercentage }})"

      # ë†’ì€ ì§€ì—° ì‹œê°„
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            rate(http_request_duration_seconds_bucket[5m])
          ) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ë†’ì€ ì§€ì—°ì‹œê°„: {{ $labels.instance }}"
          description: "P95 ì§€ì—°ì‹œê°„ì´ 1ì´ˆ ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }}s)"

  - name: resource_usage
    interval: 30s
    rules:
      # ë†’ì€ CPU ì‚¬ìš©ë¥ 
      - alert: HighCPUUsage
        expr: |
          (
            rate(process_cpu_seconds_total[5m]) * 100
          ) > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ë†’ì€ CPU ì‚¬ìš©ë¥ : {{ $labels.instance }}"
          description: "CPU ì‚¬ìš©ë¥ ì´ 80% ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }}%)"

      # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
      - alert: HighMemoryUsage
        expr: |
          (
            process_resident_memory_bytes
            /
            node_memory_MemTotal_bytes
          ) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {{ $labels.instance }}"
          description: "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ 80% ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }}%)"

      # ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
      - alert: DiskSpaceLow
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/"}
            /
            node_filesystem_size_bytes{mountpoint="/"}
          ) * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±: {{ $labels.instance }}"
          description: "ë£¨íŠ¸ íŒŒí‹°ì…˜ ë‚¨ì€ ê³µê°„ì´ 10% ë¯¸ë§Œì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }}%)"

  - name: database
    interval: 30s
    rules:
      # PostgreSQL ì—°ê²° ê³¼ë‹¤
      - alert: PostgresTooManyConnections
        expr: |
          (
            pg_stat_database_numbackends
            /
            pg_settings_max_connections
          ) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQL ì—°ê²° ê³¼ë‹¤"
          description: "ì—°ê²° ìˆ˜ê°€ ìµœëŒ€ì˜ 80% ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }}%)"

      # PostgreSQL ì¿¼ë¦¬ ëŠë¦¼
      - alert: PostgresSlowQueries
        expr: |
          rate(pg_stat_statements_mean_exec_time_seconds[5m]) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQL ëŠë¦° ì¿¼ë¦¬"
          description: "í‰ê·  ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ì´ 1ì´ˆ ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }}s)"

  - name: celery
    interval: 30s
    rules:
      # Celery Task Queue ê¸¸ì´
      - alert: CeleryQueueBacklog
        expr: celery_queue_length > 1000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Celery Queue ë°€ë¦¼"
          description: "ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ì´ 1000ê°œ ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }})"

      # Celery Worker ë‹¤ìš´
      - alert: CeleryWorkerDown
        expr: celery_worker_up == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Celery Worker ë‹¤ìš´"
          description: "Celery Workerê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

  - name: websocket
    interval: 30s
    rules:
      # WebSocket ì—°ê²° ê¸‰ì¦
      - alert: WebSocketConnectionSpike
        expr: |
          rate(websocket_connections_total[5m]) > 100
        for: 2m
        labels:
          severity: info
        annotations:
          summary: "WebSocket ì—°ê²° ê¸‰ì¦"
          description: "WebSocket ì—°ê²°ì´ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤ ({{ $value }}/s)"

      # WebSocket ì—°ê²° ìˆ˜ ì´ìƒ
      - alert: TooManyWebSocketConnections
        expr: websocket_connections_active > 5000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "WebSocket ì—°ê²° ê³¼ë‹¤"
          description: "í™œì„± WebSocket ì—°ê²°ì´ 5000ê°œ ì´ìƒì…ë‹ˆë‹¤ (í˜„ì¬: {{ $value }})"
```

### 3.4 AlertManager ì„¤ì •

```yaml
# docker/compose/config/alertmanager/alertmanager.yml

global:
  resolve_timeout: 5m
  slack_api_url: '${SLACK_WEBHOOK_URL}'

# ì•Œë¦¼ ë¼ìš°íŒ…
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'

  routes:
    # Critical ì•Œë¦¼ (ì¦‰ì‹œ)
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 5m

    # Warning ì•Œë¦¼ (5ë¶„ ëŒ€ê¸°)
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 5m
      repeat_interval: 1h

    # Info ì•Œë¦¼ (1ì‹œê°„ ëŒ€ê¸°)
    - match:
        severity: info
      receiver: 'info-alerts'
      group_wait: 1h
      repeat_interval: 24h

# ìˆ˜ì‹ ì ì„¤ì •
receivers:
  - name: 'default'
    slack_configs:
      - channel: '#alerts'
        title: 'ğŸš¨ {{ .GroupLabels.alertname }}'
        text: |
          *Summary*: {{ .CommonAnnotations.summary }}
          *Description*: {{ .CommonAnnotations.description }}
          *Severity*: {{ .CommonLabels.severity }}

  - name: 'critical-alerts'
    slack_configs:
      - channel: '#alerts-critical'
        send_resolved: true
        title: 'ğŸ”´ CRITICAL: {{ .GroupLabels.alertname }}'
        color: 'danger'
        text: |
          *Summary*: {{ .CommonAnnotations.summary }}
          *Description*: {{ .CommonAnnotations.description }}
          *Severity*: {{ .CommonLabels.severity }}
    email_configs:
      - to: 'admin@ralphpark.com'
        send_resolved: true

  - name: 'warning-alerts'
    slack_configs:
      - channel: '#alerts-warning'
        send_resolved: true
        title: 'âš ï¸ WARNING: {{ .GroupLabels.alertname }}'
        color: 'warning'
        text: |
          *Summary*: {{ .CommonAnnotations.summary }}
          *Description*: {{ .CommonAnnotations.description }}

  - name: 'info-alerts'
    slack_configs:
      - channel: '#alerts-info'
        send_resolved: true
        title: 'â„¹ï¸ INFO: {{ .GroupLabels.alertname }}'

# ì–µì œ ê·œì¹™ (ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€)
inhibit_rules:
  # Criticalì´ ë°œìƒí•˜ë©´ related ì–µì œ
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
```

---

## 4. Grafana ëŒ€ì‹œë³´ë“œ

### 4.1 Dashboard ëª©ë¡

| Dashboard | ëª©ì  | ì£¼ìš” íŒ¨ë„ |
|-----------|------|-----------|
| **System Overview** | ì „ì²´ ì‹œìŠ¤í…œ í˜„í™© | CPU, Memory, Disk, Network |
| **Service Health** | ì„œë¹„ìŠ¤ ìƒíƒœ | Uptime, Request Rate, Error Rate |
| **API Performance** | API ì„±ëŠ¥ | Latency, Throughput, Status Codes |
| **Database** | PostgreSQL | Connections, Queries, Cache Hit Ratio |
| **Celery** | ë°°ì¹˜ ì‘ì—… | Task Rate, Worker Status, Queue Length |
| **WebSocket** | ì‹¤ì‹œê°„ ì—°ê²° | Connections, Messages, Broadcast Time |
| **Kiwoom Integration** | ì™¸ë¶€ API | Rate Limit, Errors, Response Time |

### 4.2 í•µì‹¬ Grafana Panel ì˜ˆì‹œ

#### System Overview Dashboard
```json
{
  "title": "System Overview",
  "panels": [
    {
      "title": "CPU Usage %",
      "targets": [
        {
          "expr": "100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)"
        }
      ],
      "type": "graph"
    },
    {
      "title": "Memory Usage %",
      "targets": [
        {
          "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100"
        }
      ],
      "type": "gauge"
    },
    {
      "title": "Disk Usage %",
      "targets": [
        {
          "expr": "(1 - (node_filesystem_avail_bytes{mountpoint=\"/\"} / node_filesystem_size_bytes{mountpoint=\"/\"})) * 100"
        }
      ],
      "type": "gauge"
    },
    {
      "title": "Network Traffic",
      "targets": [
        {
          "expr": "rate(node_network_receive_bytes_total[5m])",
          "legendFormat": "In {{instance}}"
        },
        {
          "expr": "rate(node_network_transmit_bytes_total[5m])",
          "legendFormat": "Out {{instance}}"
        }
      ],
      "type": "graph"
    }
  ]
}
```

#### Service Health Dashboard
```json
{
  "title": "Service Health",
  "panels": [
    {
      "title": "Service Uptime",
      "targets": [
        {
          "expr": "up{job=~\"api-gateway|vcp-scanner|signal-engine|chatbot|daytrading-scanner\"}"
        }
      ],
      "type": "stat"
    },
    {
      "title": "Request Rate (req/s)",
      "targets": [
        {
          "expr": "sum(rate(http_requests_total[5m])) by (job)"
        }
      ],
      "type": "graph"
    },
    {
      "title": "Error Rate (%)",
      "targets": [
        {
          "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (job) / sum(rate(http_requests_total[5m])) by (job) * 100"
        }
      ],
      "type": "gauge"
    },
    {
      "title": "P95 Latency (s)",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job))"
        }
      ],
      "type": "graph"
    }
  ]
}
```

### 4.3 Grafana Provisioning

```yaml
# docker/compose/config/grafana/provisioning/dashboards/dashboard.yml

apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    options:
      path: /etc/grafana/provisioning/dashboards
```

```yaml
# docker/compose/config/grafana/provisioning/datasources/prometheus.yml

apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
```

---

## 5. ELK Stack êµ¬ì„±

### 5.1 Docker Compose ì¶”ê°€

```yaml
# docker/compose/services/logging.yml

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
    container_name: elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - ralph-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.12.0
    container_name: logstash
    restart: unless-stopped
    volumes:
      - ./config/logstash:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch
    networks:
      - ralph-network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.0
    container_name: kibana
    restart: unless-stopped
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - ralph-network

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.12.0
    container_name: filebeat
    restart: unless-stopped
    user: root
    volumes:
      - ./config/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: filebeat -e -strict.perms=false
    networks:
      - ralph-network

volumes:
  elasticsearch-data:
    name: ralph-elasticsearch-data
```

### 5.2 Filebeat ì„¤ì •

```yaml
# docker/compose/config/filebeat/filebeat.yml

filebeat.inputs:
  - type: container
    paths:
      - /var/lib/docker/containers/*/*.log
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

# Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ë§Œ ìˆ˜ì§‘
processors:
  - drop_event:
      when:
        not:
          or:
            - equals:
                docker.container.name: "api-gateway"
            - equals:
                docker.container.name: "vcp-scanner"
            - equals:
                docker.container.name: "signal-engine"
            - equals:
                docker.container.name: "daytrading-scanner"
            - equals:
                docker.container.name: "chatbot"
            - equals:
                docker.container.name: "frontend"
            - equals:
                docker.container.name: "celery-worker"
            - equals:
                docker.container.name: "celery-beat"

  # ë¡œê·¸ ë ˆë²¨ íŒŒì‹±
  - dissect:
      tokenizer: '%{timestamp} - %{logger} - %{level} - %{message}'
      field: "message"
      target_prefix: "parsed"

# Logstashë¡œ ì „ì†¡
output.logstash:
  hosts: ["logstash:5044"]

# Kibana ëŒ€ì‹œë³´ë“œ ìë™ ì„¤ì •
setup.kibana:
  host: "http://kibana:5601"

# ì¸ë±ìŠ¤ ì„¤ì •
output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "ralph-stock-logs-%{+yyyy.MM.dd}"
  setup.template.name: "ralph-stock"
  setup.template.pattern: "ralph-stock-*"

# ë¡œê·¸ ìˆ˜ì§‘ ì£¼ê¸°
logging.level: info
logging.metrics.enabled: false
```

### 5.3 Logstash íŒŒì´í”„ë¼ì¸

```ruby
# docker/compose/config/logstash/pipeline.conf

input {
  beats {
    port => 5044
  }
}

filter {
  # JSON íŒŒì‹±
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }

  # Docker ë©”íƒ€ë°ì´í„° ì¶”ê°€
  if [docker][container][name] {
    mutate {
      add_field => {
        "service" => "%{[docker][container][name]}"
      }
    }
  }

  # ë¡œê·¸ ë ˆë²¨ íŒŒì‹± (Python ë¡œê·¸ í˜•ì‹)
  grok {
    match => {
      "message" => "(?<timestamp>%{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{TIME}) - (?<logger>[^ ]+) - (?<level>[^ ]+) - (?<message>.*)"
    }
  }

  # ë‚ ì§œ íŒŒì‹±
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # ì—ëŸ¬ ë¡œê·¸ íƒœê·¸
  if [level] == "ERROR" or [level] == "CRITICAL" {
    mutate {
      add_tag => ["error"]
    }
  }

  # Kiwoom API ê´€ë ¨ ë¡œê·¸
  if [message] =~ /Kiwoom/ {
    mutate {
      add_tag => ["kiwoom"]
    }
  }

  # WebSocket ë¡œê·¸
  if [message] =~ /WebSocket/ {
    mutate {
      add_tag => ["websocket"]
    }
  }

  # ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
  mutate {
    remove_field => ["agent", "ecs", "host", "@version"]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ralph-stock-logs-%{+YYYY.MM.dd}"

    # ì—ëŸ¬ ë¡œê·¸ëŠ” ë³„ë„ ì¸ë±ìŠ¤
    if "error" in [tags] {
      index => "ralph-stock-errors-%{+YYYY.MM.dd}"
    }
  }

  # ë””ë²„ê¹…ìš© stdout
  stdout {
    codec => rubydebug
  }
}
```

---

## 6. Health Check ê°œì„ 

### 6.1 í†µí•© í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸

```python
# services/api_gateway/health.py

from fastapi import APIRouter, HTTPException
from typing import Dict, Any
import httpx
from sqlalchemy import text
from src.database.session import get_db_session

router = APIRouter()

@router.get("/health")
async def health_check():
    """
    í†µí•© í—¬ìŠ¤ì²´í¬
    - ì„œë¹„ìŠ¤ ìƒíƒœ
    - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    - Redis ì—°ê²°
    - ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²°
    """
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "checks": {}
    }

    # PostgreSQL ì²´í¬
    try:
        async with get_db_session() as db:
            result = await db.execute(text("SELECT 1"))
            health_status["checks"]["postgres"] = {
                "status": "healthy",
                "latency_ms": result.elapsed * 1000 if hasattr(result, 'elapsed') else 0
            }
    except Exception as e:
        health_status["checks"]["postgres"] = {
            "status": "unhealthy",
            "error": str(e)
        }
        health_status["status"] = "unhealthy"

    # Redis ì²´í¬
    try:
        redis_client.ping()
        health_status["checks"]["redis"] = {"status": "healthy"}
    except Exception as e:
        health_status["checks"]["redis"] = {
            "status": "unhealthy",
            "error": str(e)
        }
        health_status["status"] = "degraded"

    # VCP Scanner ì²´í¬
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{settings.vcp_scanner_url}/health",
                timeout=2.0
            )
            health_status["checks"]["vcp_scanner"] = {
                "status": "healthy" if response.status_code == 200 else "unhealthy"
            }
    except Exception as e:
        health_status["checks"]["vcp_scanner"] = {
            "status": "unhealthy",
            "error": str(e)
        }

    # Signal Engine ì²´í¬
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{settings.signal_engine_url}/health",
                timeout=2.0
            )
            health_status["checks"]["signal_engine"] = {
                "status": "healthy" if response.status_code == 200 else "unhealthy"
            }
    except Exception as e:
        health_status["checks"]["signal_engine"] = {
            "status": "unhealthy",
            "error": str(e)
        }

    return health_status

@router.get("/health/ready")
async def readiness_check():
    """
    Readiness Probe
    - íŠ¸ë˜í”½ ë°›ì„ ì¤€ë¹„ ë˜ì—ˆëŠ”ì§€
    """
    # DB ì—°ê²°ë§Œ í™•ì¸
    try:
        async with get_db_session() as db:
            await db.execute(text("SELECT 1"))
        return {"status": "ready"}
    except Exception:
        raise HTTPException(status_code=503, detail="not ready")

@router.get("/health/live")
async def liveness_check():
    """
    Liveness Probe
    - í”„ë¡œì„¸ìŠ¤ ì‚´ì•„ìˆëŠ”ì§€
    """
    return {"status": "alive"}
```

### 6.2 Docker Compose Health Check ì—…ë°ì´íŠ¸

```yaml
# docker/compose/profiles/prod.yml

services:
  api-gateway:
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5111/health/ready"]
      interval: 15s
      timeout: 5s
      start_period: 60s
      retries: 3

  celery-worker:
    healthcheck:
      test: ["CMD", "celery", "-A", "tasks.celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3
```

---

## 7. êµ¬í˜„ Phase

### Phase 1: Prometheus + Grafana (Week 1)
- [ ] Docker Composeì— ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì¶”ê°€
- [ ] Prometheus ì„¤ì •
- [ ] AlertManager ì„¤ì •
- [ ] Grafana ì„¤ì¹˜ ë° Provisioning
- [ ] í•µì‹¬ Dashboard ìƒì„±
- [ ] Slack ì•Œë¦¼ ì—°ë™

### Phase 2: Exporter ë°°í¬ (Week 1-2)
- [ ] Node Exporter ë°°í¬
- [ ] cAdvisor ë°°í¬
- [ ] PostgreSQL Exporter ë°°í¬
- [ ] Redis Exporter ë°°í¬
- [ ] FastAPI /metrics ì—”ë“œí¬ì¸íŠ¸ ì ê²€

### Phase 3: Alert ê·œì¹™ (Week 2)
- [ ] Service Health Alert
- [ ] Resource Usage Alert
- [ ] Database Alert
- [ ] Celery Alert
- [ ] WebSocket Alert

### Phase 4: ELK Stack (Week 3-4)
- [ ] Elasticsearch ì„¤ì¹˜
- [ ] Logstash ì„¤ì¹˜
- [ ] Kibana ì„¤ì¹˜
- [ ] Filebeat ì„¤ì •
- [ ] ë¡œê·¸ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### Phase 5: ê³ ê¸‰ ê¸°ëŠ¥ (Week 5+)
- [ ] Grafana Loki (ì„ íƒ)
- [ ] Jaeger Tracing (ì„ íƒ)
- [ ] PagerDuty ì—°ë™ (ì„ íƒ)
- [ ] SMS ì•Œë¦¼ (ì„ íƒ)

---

## 8. í¬íŠ¸ ë§¤í•‘

| ì„œë¹„ìŠ¤ | í¬íŠ¸ | ì„¤ëª… |
|--------|------|------|
| Prometheus | 9090 | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ |
| Grafana | 3000 | ëŒ€ì‹œë³´ë“œ |
| AlertManager | 9093 | ì•Œë¦¼ ê´€ë¦¬ |
| Node Exporter | 9100 | ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ |
| cAdvisor | 9800 | ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­ |
| PostgreSQL Exporter | 9187 | DB ë©”íŠ¸ë¦­ |
| Redis Exporter | 9121 | Redis ë©”íŠ¸ë¦­ |
| Elasticsearch | 9200 | ë¡œê·¸ ì €ì¥ì†Œ |
| Kibana | 5601 | ë¡œê·¸ ëŒ€ì‹œë³´ë“œ |
| Logstash | 5044 | ë¡œê·¸ ìˆ˜ì§‘ |

---

## 9. ë¦¬ì†ŒìŠ¤ ì˜ˆìƒ

### 9.1 ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë¦¬ì†ŒìŠ¤

| ì„œë¹„ìŠ¤ | CPU | Memory | Disk |
|--------|-----|--------|------|
| Prometheus | 2 core | 2GB | 50GB/30ì¼ |
| Grafana | 1 core | 512MB | 1GB |
| AlertManager | 0.5 core | 256MB | 1GB |
| Node Exporter | 0.1 core | 64MB | - |
| cAdvisor | 0.5 core | 256MB | - |
| PostgreSQL Exporter | 0.1 core | 64MB | - |
| Redis Exporter | 0.1 core | 64MB | - |
| Elasticsearch | 2 core | 2GB | 100GB/30ì¼ |
| Logstash | 1 core | 1GB | - |
| Kibana | 1 core | 1GB | 1GB |
| Filebeat | 0.1 core | 64MB | - |
| **ì´ê³„** | **8.5 core** | **~8GB** | **~150GB** |

---

## 10. ê²°ë¡ 

### 10.1 ê¸°ëŒ€ íš¨ê³¼
- âœ… ì¥ì•  ê°ì§€ ì‹œê°„: 1ë¶„ ì´ë‚´
- âœ… ëª¨ë‹ˆí„°ë§ ì»¤ë²„ë¦¬ì§€: 100%
- âœ… ë¡œê·¸ ê²€ìƒ‰: ì‹¤ì‹œê°„
- âœ… ì„±ëŠ¥ ë³‘ëª© ì‹ë³„: ê°€ëŠ¥
- âœ… ìš©ëŸ‰ ê³„íš: ë°ì´í„° ê¸°ë°˜

### 10.2 ë‹¤ìŒ ë‹¨ê³„
1. **ì¦‰ì‹œ**: Phase 1-2 (Prometheus + Grafana + Exporters)
2. **2ì£¼ ë‚´**: Phase 3 (Alert Rules)
3. **í•œë‹¬ ë‚´**: Phase 4 (ELK Stack)

---

*ì´ ì„¤ê³„ì„œëŠ” DevOps Architectì— ì˜í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
